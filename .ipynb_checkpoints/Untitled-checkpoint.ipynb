{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from random import shuffle\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_images = []\n",
    "non_vehicle_images = []\n",
    "\n",
    "if (os.path.isfile('vehicle_images.npy') and os.path.isfile('non_vehicle_images.npy')):\n",
    "    print('Loading pre-loaded array...')\n",
    "    vehicle_images = np.load('vehicle_images.npy')\n",
    "    non_vehicle_images = np.load('non_vehicle_images.npy')\n",
    "else:\n",
    "    for path, subdirs, files in os.walk('vehicles'):\n",
    "        for name in files:\n",
    "            if name.endswith('.png'):\n",
    "#                 vehicle_images.append(cv2.cvtColor(cv2.imread(os.path.join(path, name)), cv2.COLOR_BGR2GRAY))\n",
    "                vehicle_images.append(cv2.imread(os.path.join(path, name)))\n",
    "    np.save('vehicle_images.npy', vehicle_images)\n",
    "    for path, subdirs, files in os.walk('non-vehicles'):\n",
    "        for name in files:\n",
    "            if name.endswith('.png'):\n",
    "                non_vehicle_images.append(cv2.imread(os.path.join(path, name)))\n",
    "    np.save('non_vehicle_images.npy', non_vehicle_images)\n",
    "\n",
    "                \n",
    "print(len(vehicle_images))\n",
    "shuffle(vehicle_images)\n",
    "shuffle(non_vehicle_images)\n",
    "vehicle_images_train = vehicle_images[:7500]\n",
    "vehicle_images_eval = vehicle_images[7500:]\n",
    "non_vehicle_images_train = non_vehicle_images[:7500]\n",
    "non_vehicle_images_eval = non_vehicle_images[7500:]\n",
    "print('# of non_vehicle_images: {}'.format(len(non_vehicle_images)))\n",
    "print('# of non_vehicle_images_train: {}'.format(len(non_vehicle_images_train)))\n",
    "print('# of non_vehicle_images_eval: {}'.format(len(non_vehicle_images_eval)))\n",
    "print('# of vehicle_images: {}'.format(len(vehicle_images)))\n",
    "print('# of vehicle_images_train: {}'.format(len(vehicle_images_train)))\n",
    "print('# of vehicle_images_eval: {}'.format(len(vehicle_images_eval)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Hog Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_space = 'HLS' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 0 # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [None, None] # Min and max in y to search in slide_window()\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                        vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "    \n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "# print(non_vehicle_images_eval[0].shape)\n",
    "# print(len(single_img_features(non_vehicle_images_eval[0], color_space=color_space, \n",
    "#                             spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "#                             orient=orient, pix_per_cell=pix_per_cell, \n",
    "#                             cell_per_block=cell_per_block, \n",
    "#                             hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "#                             hist_feat=hist_feat, hog_feat=hog_feat)))\n",
    "\n",
    "hog_non_vehicle_images_eval = []\n",
    "if os.path.isfile('hog_non_vehicle_images_eval.npy'):\n",
    "    print('Loading hog_non_vehicle_images_eval...')\n",
    "    hog_non_vehicle_images_eval = np.load('hog_non_vehicle_images_eval.npy')\n",
    "else:\n",
    "    for image in non_vehicle_images_eval:\n",
    "        features = single_img_features(image, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        hog_non_vehicle_images_eval.append(features.flatten())\n",
    "    np.save('hog_non_vehicle_images_eval.npy', hog_non_vehicle_images_eval)\n",
    "    print('Saving hog_non_vehicle_images_eval...')\n",
    "\n",
    "\n",
    "hog_non_vehicle_images_train = []\n",
    "if os.path.isfile('hog_non_vehicle_images_train.npy'):\n",
    "    print('Loading hog_non_vehicle_images_train...')\n",
    "    hog_non_vehicle_images_train = np.load('hog_non_vehicle_images_train.npy')\n",
    "else:\n",
    "    for image in non_vehicle_images_train:\n",
    "        features = single_img_features(image, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        hog_non_vehicle_images_train.append(features.flatten())\n",
    "    np.save('hog_non_vehicle_images_train.npy', hog_non_vehicle_images_train)\n",
    "    print('Saving hog_non_vehicle_images_train...')\n",
    "\n",
    "hog_vehicle_images_train = []\n",
    "if os.path.isfile('hog_vehicle_images_train.npy'):\n",
    "    print('Loading hog_vehicle_images_train...')\n",
    "    hog_vehicle_images_train = np.load('hog_vehicle_images_train.npy')\n",
    "else:\n",
    "    for image in vehicle_images_train:\n",
    "        features = single_img_features(image, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        hog_vehicle_images_train.append(features.flatten())\n",
    "    np.save('hog_vehicle_images_train.npy', hog_vehicle_images_train)\n",
    "    print('Saving hog_vehicle_images_train...')\n",
    "    \n",
    "hog_vehicle_images_eval = []\n",
    "if os.path.isfile('hog_vehicle_images_eval.npy'):\n",
    "    print('Loading hog_vehicle_images_eval...')\n",
    "    hog_vehicle_images_eval = np.load('hog_vehicle_images_eval.npy')\n",
    "else:\n",
    "    for image in vehicle_images_eval:\n",
    "        features = single_img_features(image, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        hog_vehicle_images_eval.append(features.flatten())\n",
    "    np.save('hog_vehicle_images_eval.npy', hog_vehicle_images_eval)\n",
    "    print('Saving hog_vehicle_images_eval...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Build SVM classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 15000\n",
    "train_features = np.vstack((hog_vehicle_images_train, hog_non_vehicle_images_train)).astype(np.float64)\n",
    "train_features_scaler = StandardScaler().fit(train_features)\n",
    "normalized_train_features = train_features_scaler.transform(train_features)\n",
    "\n",
    "train_target = np.append(np.ones(len(hog_vehicle_images_train)), np.zeros(len(hog_non_vehicle_images_train)))\n",
    "\n",
    "assert len(normalized_train_features) == len(train_target)\n",
    "p1 = np.random.permutation(len(normalized_train_features))\n",
    "\n",
    "train_target = train_target[p1]\n",
    "normalized_train_features = normalized_train_features[p1]\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svr = svm.SVC()\n",
    "time1 = time.time()\n",
    "svr.fit(normalized_train_features[:NUM_TRAIN], train_target[:NUM_TRAIN])\n",
    "time2 = time.time()\n",
    "print('Train SVM function took %0.3f s' % (time2-time1))\n",
    "# clf = grid_search.GridSearchCV(svr, parameters)\n",
    "# clf.fit(train_features, train_target)\n",
    "\n",
    "NUM_EVAL = 2760\n",
    "eval_features = np.vstack((hog_vehicle_images_eval, hog_non_vehicle_images_eval)).astype(np.float64)\n",
    "normalized_eval_features = train_features_scaler.transform(eval_features)\n",
    "eval_target = np.append(np.ones(len(hog_vehicle_images_eval)), np.zeros(len(hog_non_vehicle_images_eval)))\n",
    "\n",
    "assert len(normalized_eval_features) == len(eval_target)\n",
    "p2 = np.random.permutation(len(normalized_eval_features))\n",
    "\n",
    "normalized_eval_features = normalized_eval_features[p2]\n",
    "eval_target = eval_target[p2]\n",
    "\n",
    "predictions = svr.predict(normalized_eval_features[:NUM_EVAL])\n",
    "\n",
    "print('Precision: {}'.format(sum(predictions == eval_target[:NUM_EVAL])/float(NUM_EVAL)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for file in os.listdir('test_images'):\n",
    "    if file.endswith('.jpg'):\n",
    "        test_image = cv2.imread(os.path.join('test_images', file))\n",
    "        test_images.append(test_image)\n",
    "print(len(test_images))\n",
    "\n",
    "frame_images = []\n",
    "for file in os.listdir('frames'):\n",
    "    if file.endswith('.jpg'):\n",
    "        frame_image = cv2.imread(os.path.join('frames', file))\n",
    "        frame_images.append(frame_image)\n",
    "print(len(frame_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_overlap = 0.8\n",
    "y_overlap = 0.8\n",
    "\n",
    "def pipeline(image):\n",
    "    imcopy = np.copy(image)\n",
    "    windows = []\n",
    "#     windows.extend(slide_window(image, x_start_stop=[830, test_images[0].shape[1]], \n",
    "#                            y_start_stop=[350, test_images[0].shape[0]], \n",
    "#                            xy_window=(300, 300), xy_overlap=(x_overlap, y_overlap)))\n",
    "#     windows.extend(slide_window(image, x_start_stop=[716, test_images[0].shape[1]], \n",
    "#                            y_start_stop=[350, 370+225], \n",
    "#                            xy_window=(225, 225), xy_overlap=(x_overlap, y_overlap)))\n",
    "#     windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "#                            y_start_stop=[350, 370+150], \n",
    "#                            xy_window=(150, 150), xy_overlap=(x_overlap, y_overlap)))\n",
    "#     windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "#                            y_start_stop=[380, 380+100], \n",
    "#                            xy_window=(100, 100), xy_overlap=(x_overlap, y_overlap)))\n",
    "#     windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "#                            y_start_stop=[390, 390+100], \n",
    "#                            xy_window=(75, 75), xy_overlap=(x_overlap, y_overlap)))\n",
    "    windows.extend(slide_window(image, x_start_stop=[830, test_images[0].shape[1]], \n",
    "                           y_start_stop=[350-75, test_images[0].shape[0]], \n",
    "                           xy_window=(300, 300), xy_overlap=(x_overlap, y_overlap)))\n",
    "    windows.extend(slide_window(image, x_start_stop=[716, test_images[0].shape[1]], \n",
    "                           y_start_stop=[350-57, 370+225+58], \n",
    "                           xy_window=(225, 225), xy_overlap=(x_overlap, y_overlap)))\n",
    "    windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "                           y_start_stop=[350-38, 370+150+38], \n",
    "                           xy_window=(150, 150), xy_overlap=(x_overlap, y_overlap)))\n",
    "    windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "                           y_start_stop=[380-30, 380+100+60], \n",
    "                           xy_window=(120, 120), xy_overlap=(x_overlap, y_overlap)))\n",
    "    windows.extend(slide_window(image, x_start_stop=[680, test_images[0].shape[1]], \n",
    "                           y_start_stop=[390-19, 390+100+38], \n",
    "                           xy_window=(75, 75), xy_overlap=(x_overlap, y_overlap)))\n",
    "    prediction_windows = []\n",
    "    for i, window in enumerate(windows):\n",
    "#         cv2.rectangle(imcopy, window[0], window[1], (0, 0, 255), 6)\n",
    "        img = cv2.resize(image[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64,64))\n",
    "        feature = single_img_features(img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        normalized_feature = train_features_scaler.transform(feature.flatten().reshape([1,-1]))\n",
    "        if svr.predict(normalized_feature) == 1:\n",
    "            prediction_windows.append(window)\n",
    "    heatmap = np.zeros((720, 1280))\n",
    "    \n",
    "    for prediction_window in prediction_windows:\n",
    "        heatmap[prediction_window[0][1]:prediction_window[1][1], prediction_window[0][0]:prediction_window[1][0]] += 1\n",
    "        \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    \n",
    "    return imcopy\n",
    "    \n",
    "for j, image in enumerate(frame_images):\n",
    "    if j > 50:\n",
    "        break\n",
    "    print('Processing {}/{} image...'.format(j, len(frame_images)))\n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(pipeline(image), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "output = 'project_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "output_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time output_clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
